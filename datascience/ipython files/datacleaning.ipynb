{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install contractions \n",
    "\n",
    "# !{sys.executable} -m pip install contractions\n",
    "\n",
    "# import sys, setuptools, tokenize\n",
    "# !pip install pycontractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# >>>>>>>>>>>>>>>>>>>>>>>>>>>>>> imports >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import re, unicodedata, string  \n",
    "# import num2word\n",
    "# import inflect\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "!pip install contractions \n",
    "# import sys\n",
    "import contractions\n",
    "# import pycontractions \n",
    "# from contractions import CONTRACTION_MAP\n",
    "# from contractions import CONTRACTION_dict\n",
    "# from pycontractions import Contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# >>>>>>>>>>>>>>>>>>>>>>>>>>>>>> loading the dataset >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "\n",
    "# filename = '../dataset/Reviews only (Sentiment).csv'\n",
    "# file = open(filename, 'rt')\n",
    "# text = file.read()\n",
    "# file.close()\n",
    "\n",
    "df = pd.read_csv('../dataset/testing.csv')\n",
    "# df_no_indices = df.to_string(index=False)\n",
    "# print(df_no_indices)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# >>>>>>>>>>>>>>>>>>>>>>>>>>>>>> removing null values >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "\n",
    "# counting rows before removing null values\n",
    "df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing null values\n",
    "# counting rows after removing null values\n",
    "df.dropna(axis=0, how=\"any\", thresh=None, subset=None, inplace=False).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# after removing null values\n",
    "# before removing URL\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# >>>>>>>>>>>>>>>>>>>>>>>>>>>>>> removing URL >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "\n",
    "def remove_URL(reviewText):\n",
    "    url = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return url.sub(r'', str(reviewText))\n",
    "\n",
    "df['reviewText'] = df['reviewText'].apply(remove_URL)\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# >>>>>>>>>>>>>>>>>>>>>>>>>>>>>> removing HTML tags >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "def remove_html(reviewText):\n",
    "    html=re.compile(r'<.*?>')\n",
    "    return html.sub(r'',str(reviewText))\n",
    "df['reviewText'] = df['reviewText'].apply(remove_html)\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# >>>>>>>>>>>>>>>>>>>>>>>>>>>>>> removing square brackets and the inside of the square bracket >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "\n",
    "def remove_between_square_brackets(reviewText):\n",
    "    return re.sub('\\[[^]]*\\]', '', str(reviewText))\n",
    "df['reviewText'] = df['reviewText'].apply(remove_between_square_brackets)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# >>>>>>>>>>>>>>>>>>>>>>>>>>>>>> removing Pictures/Tags/Symbols/Emojis >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "\n",
    "def remove_emoji(reviewText):\n",
    "    emoj = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "        u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U000024C2-\\U0001F251\"\n",
    "        u\"\\U0001f926-\\U0001f937\"\n",
    "        u\"\\U00010000-\\U0010ffff\"\n",
    "        u\"\\u2640-\\u2642\" \n",
    "        u\"\\u2600-\\u2B55\"\n",
    "        u\"\\u200d\"\n",
    "        u\"\\u23cf\"\n",
    "        u\"\\u23e9\"\n",
    "        u\"\\u231a\"\n",
    "        u\"\\ufe0f\"  # dingbats\n",
    "        u\"\\u3030\"\n",
    "                      \"]+\", re.UNICODE)\n",
    "    return re.sub(emoj, '', str(reviewText))\n",
    "\n",
    "df['reviewText'] = df['reviewText'].apply(remove_emoji)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# >>>>>>>>>>>>>>>>>>>>>>>>>>>>>> expand contractions >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "\n",
    "# def expand_contractions(reviewText):\n",
    "#     contractionsPattern = re.compile('({})'.format('|'.join(CONTRACTION_MAP.keys())),flags=re.IGNORECASE|re.DOTALL)\n",
    "#     def expand_match(contraction):\n",
    "#         match = contraction.group(0)\n",
    "#         firstChar = match[0]\n",
    "#         expandedContraction = CONTRACTION_MAP.get(match)\\\n",
    "#                         if CONTRACTION_MAP.get(match)\\\n",
    "#                         else CONTRACTION_MAP.get(match.lower())\n",
    "#         expandedContraction = firstChar+expandedContraction[1:]\n",
    "#         return expandedContraction\n",
    "    \n",
    "#     reviewText = contractionsPattern.sub(expand_match, str(reviewText))\n",
    "#     reviewText = re.sub(\"'\", \"\", reviewText)\n",
    "#     return reviewText\n",
    "\n",
    "# df['reviewText'] = df['reviewText'].apply(expand_contractions)\n",
    "# df.head(10)\n",
    "\n",
    "# cont = Contractions('GoogleNews-vectors-negative300.bin')\n",
    "expanded_words = []    \n",
    "for word in df:\n",
    "#     expanded_words.append(list(cont.expand_texts([word], precise=True))) \n",
    "    expanded_words.append(contractions.fix(word)) \n",
    "print(expanded_words[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# >>>>>>>>>>>>>>>>>>>>>>>>>>>>>> tokenizing words >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "\n",
    "# ndf = df['reviewText']\n",
    "tokens = word_tokenize(str(df))\n",
    "print(tokens[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# >>>>>>>>>>>>>>>>>>>>>>>>>>>>>> removing non ascii >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "\n",
    "removedNonAscii = [w.encode(\"ascii\", \"ignore\").decode() for w in tokens]\n",
    "print(removedNonAscii[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# >>>>>>>>>>>>>>>>>>>>>>>>>>>>>> convert to lower case >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "\n",
    "lowerCase = [w.lower() for w in removedNonAscii]\n",
    "print(lowerCase[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# >>>>>>>>>>>>>>>>>>>>>>>>>>>>>> removing punctuation >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "\n",
    "table = str.maketrans('', '', string.punctuation)\n",
    "removedPunctuation = [w.translate(table) for w in lowerCase]\n",
    "print(removedPunctuation[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# >>>>>>>>>>>>>>>>>>>>>>>>>>>>>> replacing numbers with string  >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "\n",
    "# p = inflect.engine()\n",
    "# stringNumbers = []\n",
    "# for word in removedPunctuation:\n",
    "#     if word.isdigit():\n",
    "# #         new_word = num2word.to_card(15)\n",
    "#         new_word = p.number_to_words(word)\n",
    "#         stringNumbers.append(new_word)\n",
    "#     else:\n",
    "#         stringNumbers.append(word)\n",
    "        \n",
    "# # stringNumbers = [w.lower() for w in removedPunctuation]\n",
    "# print(stringNumbers[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# >>>>>>>>>>>>>>>>>>>>>>>>>>>>>> removing stopwords >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "removedStopwords = [w for w in removedPunctuation if not w in stop_words]\n",
    "print(removedStopwords[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# >>>>>>>>>>>>>>>>>>>>>>>>>>>>>> stemming words >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "\n",
    "stemmer = LancasterStemmer()\n",
    "stems = []\n",
    "for word in removedStopwords:\n",
    "    stem = stemmer.stem(word)\n",
    "    stems.append(stem)\n",
    "    \n",
    "print(stems[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# >>>>>>>>>>>>>>>>>>>>>>>>>>>>>> lemmatize_verbs >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmas = []\n",
    "for word in stems:\n",
    "    lemma = lemmatizer.lemmatize(word, pos='v')\n",
    "    lemmas.append(lemma)\n",
    "    \n",
    "print(lemmas[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
